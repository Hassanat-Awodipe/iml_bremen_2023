{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaac83ca",
   "metadata": {},
   "source": [
    "# Interpretable Machine Learning\n",
    "## Exercise Sheet 6: LIME\n",
    "## This exercise sheet covers lecture 6 on LIME\n",
    "Sophie Langbein (langbein@leibniz-bips.de)<br>\n",
    "Pegah Golchian (golchian@leibniz-bips.de)\n",
    "<hr style=\"border:1.5px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d230b3e",
   "metadata": {},
   "source": [
    "# Counterfactual Explanations\n",
    "\n",
    "Counterfactual explanations are a valuable tool to explain predictions of machine learning models. They provide an understanding of how a machine learning model's prediction for a specific instance would change if the input features were altered in a meaningful way. These explanations are generated by identifying a \"counterfactual\" instance, which is a data point that is as similar as possible to the original instance but with some feature values modified. The goal is to explain to end-users how they could change their input to receive a different model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131d3cd",
   "metadata": {},
   "source": [
    "One of the simplest approaches to generate counterfactuals is to determine for a given observation x (`x_interest`) the closest data point which has a prediction equal to the desired outcome. In the following exercise, you should implement this so called **WhatIf** approach for a binary classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ec6c7",
   "metadata": {},
   "source": [
    "**a)** Implement the following steps in `generate_whatif()`:\n",
    "\n",
    "- Create a dataset containing only the values with a prediction different to the one of `x_interest` (this is equal to our desired prediction).\n",
    "- Calculate the pairwise Gower’s distances between `x_interest` and all other points with differing predictions.\n",
    "- Return the nearest data point as a counterfactual for `x_interest` with the shape (1, num_features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f922c",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b36f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "import numpy as np\n",
    "\n",
    "def generate_whatif(x_interest, model, dataset): \n",
    "  \n",
    "    \"\"\"\n",
    "    Computes whatif counterfactuals for binary classification models, \n",
    "    i.e., the closest data point with a different prediction.\n",
    "  \n",
    "    Parameters: \n",
    "    x_interest (np.array with shape (1, num_features)): Datapoint of interest.\n",
    "    model: Binary classifier which has a predict method.\n",
    "    dataset (np.array with shape (?, num_features)): Input data from which a counterfactual is selected.\n",
    "\n",
    "    Returns:\n",
    "    counterfactual (np.array with shape (1, num_features)): the closest observation/row to x_interest of the input dataset with a different prediction than x_interest. \n",
    "    \"\"\"\n",
    "    \n",
    "    # fill in \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec54846",
   "metadata": {},
   "source": [
    "**b)** Write a function `evaluate_counterfactual()` to evaluate whether a counterfactual is minimal. In other words, the function should check, if setting one feature to the value of `x_interest`, still results in a different prediction than for `x_interest`. It should return a list with names of features that if set for the counterfactual to the value of `x_interest`, still lead to a different prediction than for `x_interest`. Hence the function should check for every feature, whether setting it equal to its value in `x_interest` leads to a different prediction than the prediction of `x_interest` and if so, record the corresponding feature value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e3baf0",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf83604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_counterfactual(counterfactual, x_interest, model, labels) :\n",
    "    \"\"\"\n",
    "    Evaluates if counterfactuals are minimal, i.e., if setting one feature to the value of x_interest still results in a different prediction than for x_interest.\n",
    "   \n",
    "    Parameters: \n",
    "    counterfactual (np.array with shape (1, num_features)): Counterfactual of `x_interest`. \n",
    "    x_interest (np.array with shape (1, num_features)): Datapoint of interest. \n",
    "    model: Binary classifier which has a predict method.\n",
    "    labels (list): A list of the labels of the feature matrix. \n",
    "  \n",
    "    Returns: \n",
    "    List with names of features that if set for the counterfactual to the value of `x_interest`, still leads to a different prediction than for x_interest. \n",
    "    \"\"\"\n",
    "\n",
    "    # fill in \n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014d134",
   "metadata": {},
   "source": [
    "**c)** Now, to test the `generate_whatif()` and `evaluate_counterfactual()` functions, import the [wheat seeds dataset](https://archive.ics.uci.edu/dataset/236/seeds) from `wheat_seeds.csv`, which was already used in Exercise Session 6. \n",
    "\n",
    "- Drop all rows that contain `NA` values. \n",
    "- Covert the dataset into a dataset suitable for binary classification, by dropping all observations of type `Canadian` (`Type` = `2`). We only want to classify whether a kernel is of type `Kama` (`Type` = `0`) or `Rosa` `Type` = `1`). \n",
    "- Fit a random forest classifier to the full dataset (no training and test set required)\n",
    "- Choose a suitable point for `x_interest`, check whether the prediction matches the true value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadcb2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09000744",
   "metadata": {},
   "source": [
    "**d)** Compute the WhatIf counterfactual of the selected observation and interpret it. Evaluate whether it is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3ef1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aab5b00",
   "metadata": {},
   "source": [
    "**e)** Which attributes from the lecture (valid, proximal/similar, sparse, plausible/likely, diverse) does this approach fulfill? Based on this, derive the advantages and disadvantages of the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309bcf35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0bfcab4",
   "metadata": {},
   "source": [
    "**f)** Now we want to use the [DiCE](https://github.com/interpretml/DiCE) (Diverse Counterfactual Explanations) package to generate counterfactual explanations for the same data. For that purpose at first:\n",
    "\n",
    "- Split the data into training and test set. \n",
    "- Fit a random forest classifier to the training data.\n",
    "- Compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528eed9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02134102",
   "metadata": {},
   "source": [
    "**g)** Now we generate the counterfactuals using the `DiCE` package. For that purpose: \n",
    "    \n",
    "- Transform the data into an appropriate format using `dice_ml.Data`.\n",
    "- Select two instances of interest from the test set for which counterfactuals should be generated (ideally they should have different outcomes).\n",
    "- Generate counterfactuals using the `exp_random.generate_counterfactuals`function. For every instance of interest three counterfactuals should be generated. Only the features `Area` and `Perimeter` should be varied, while all other features should remain constant. \n",
    "- Visualize the counterfactuals as dataframes. \n",
    "\n",
    "Hint: In this [notebook](https://github.com/interpretml/DiCE/blob/main/docs/source/notebooks/DiCE_model_agnostic_CFs.ipynb) you can find a tutorial on how to generate DiCE counterfactuals using three different algorithms, you can chose the algorithm you prefer, random feature sampling is recommended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec4ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdb48648",
   "metadata": {},
   "source": [
    "**h)** Which attributes from the lecture (valid, proximal/similar, sparse, plausible/likely, diverse) do the counterfactuals generated above fulfill?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccede3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3eeb697",
   "metadata": {},
   "source": [
    "<hr style=\"border:1.5px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c475a",
   "metadata": {},
   "source": [
    "# Adversarial Examples\n",
    "\n",
    "Adversarial examples are inputs to machine learning models that are intentionally crafted to cause the model to make mistakes. These inputs are carefully designed to be very similar to genuine data instances but are subtly perturbed in ways that are imperceptible to humans. Adversarial examples have gained significant attention in the field of artificial intelligence and machine learning because they highlight vulnerabilities in the robustness of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9411300",
   "metadata": {},
   "source": [
    "Adversarial Examples are carefully constructed inputs that “fool” a trained model. In this exercise, your task is to generate adversarial examples using the Fast-Gradient-Sign-Method:\n",
    "\n",
    "$$\n",
    "\\mathbf{a}_\\mathbf{x} ← \\mathbf{x} + \\delta \n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\delta = \\epsilon \\cdot \\text{sign}(\\nabla_{\\mathbf{x}}J(\\mathbf{x}, y_{\\mathbf{x}}; \\theta)) \n",
    "$$\n",
    "\n",
    "with a cost function J (here, we will use cross entropy loss). This is an untargeted method, which means the resulting class label is not specified in advance. The goal is to create an adversarial input that is indistinguishable (to the human eye) from an original input, but confuses the model. In particular, we will create adversarial examples to fool an image classifier trained on the ImageNet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e4a16",
   "metadata": {},
   "source": [
    "**a)** First import all relevant modules including the custom functions from the `utils.dataset` module. Implement the `get_gradient()` function. The function should take the original `image` and the fitted `model` as an input and return the gradient of the loss with respect to the image. It should perform the following steps:\n",
    "\n",
    "- Obtain a prediction for the input `image` tensor\n",
    "- Set the `requires_grad` attribute of the `image` tensor to `True`\n",
    "- Pass the image tensor through the model to obtain its output\n",
    "- Compute the cross-entropy loss between the model outputs of the image tensor and the prediction obtained for the input image using the `torch.nn.functional.cross_entropy` function\n",
    "- Perform backpropagation to compute the gradients of the loss with respect to the input image tensor\n",
    "- Return the gradient of the loss with respect to the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e77b0",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1340dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe1e90a9410>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All relevant imports\n",
    "import sys\n",
    "import os  # noqa\n",
    "sys.path.insert(0, \"\")  # noqa\n",
    "\n",
    "import torch\n",
    "\n",
    "# These are custom modules included in the exercises session\n",
    "from utils.styled_plot import plt\n",
    "from utils.dataset import (\n",
    "    load_test_image,\n",
    "    preprocess_image,\n",
    "    normalize_image,\n",
    "    unnormalize_image,\n",
    "    convert_idx_to_label\n",
    ")\n",
    "from classifiers.cnn_classifier import ImageNetClassifier\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc6adc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(model, image):\n",
    "    \"\"\"\n",
    "    Propagates the cross entropy loss between the model's output (logits) and the label (here the label\n",
    "    that is predicted by the model is used) back to the input to get the input gradient.\n",
    "\n",
    "    Parameters:\n",
    "        model (ImageNetClassifier, torch.nn.Module):\n",
    "            The image classification model. This is a torch.nn.Module, so you can call its forward method using\n",
    "            `model()`. The output are logits (class probabilities). Also has a `.predict` method that returns the\n",
    "            index of the predicted label.\n",
    "\n",
    "        image (torch.tensor): The input for which to compute the gradient.\n",
    "\n",
    "    Returns:\n",
    "        gradient (torch.tensor): The input gradient. Same shape as the input image.\n",
    "    \"\"\"\n",
    "\n",
    "    # fill in \n",
    "    \n",
    "    return image.grad # return the gradient of the loss with respect to the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37676f72",
   "metadata": {},
   "source": [
    "**b)** Complete the `perturb_image()` function. It should perform the following steps: \n",
    "\n",
    "- Calculate the sign of each element in the input `grad` tensor as the perturbation\n",
    "- Scale the sign of the gradient using `eps`\n",
    "- Add the scaled pertubation to the original input `image` to create the perturbed image\n",
    "- Return the perturbed image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608fcc1",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "059736a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_image(image, grad, eps):\n",
    "    \"\"\"\n",
    "    Applies a perturbation to an image based on the Fast-Gradient-Sign-Method.\n",
    "\n",
    "    Parameters:\n",
    "        image (torch.tensor): The image to perturb.\n",
    "\n",
    "        grad (torch.tensor): The input gradient corresponding to the image.\n",
    "\n",
    "        eps (float): The epsilon value for the perturbation, specifying the magnitude of the perturbation.\n",
    "\n",
    "    Returns:\n",
    "        image (torch.tensor): The perturbed image.\n",
    "    \"\"\"\n",
    "\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992aeba6",
   "metadata": {},
   "source": [
    "**c)** Complete the `create_adversarials()` function. It should perform the following steps: \n",
    "\n",
    "- Calculate the gradient of the model's output with respect to the input image using the `get_gradient()` function.\n",
    "- Create a list of adversarial examples by perturbing the input image for each epsilon value in `eps_values` using the `perturb_image()` function.\n",
    "- Return the list of adversarial examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28ad05",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a302d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarials(model, image, eps_values):\n",
    "    \"\"\"\n",
    "    Creates adversarial examples for the given image and model using the Fast-Gradient-Sign-Method.\n",
    "\n",
    "    Parameters:\n",
    "        model (ImageNetClassifier, torch.nn.Module):\n",
    "            The image classification model. This is a torch.nn.Module, so you can call its forward method using `model()`.\n",
    "            Also has a `.predict` method that returns the index of the predicted label.\n",
    "\n",
    "        image (torch.tensor): The image to generate adversarial examples from.\n",
    "\n",
    "        eps_values (List[float]): The list of epsilon values for which to generate adversarial examples.\n",
    "\n",
    "    Returns:\n",
    "        adversarials (List[torch.tensor]): A list containing one adversarial example for each eps value in eps_values.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    return adversarials # return a list of adversarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566f2d5",
   "metadata": {},
   "source": [
    "**d)** Familiarize yourself with the `plot_adversarials()` functions, which is used to plot the original image and the adversarial images in a single row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1e5b8",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b823cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adversarials(model, image, adv_images, eps_values):\n",
    "    \"\"\"\n",
    "    Plots the  original image and the adversarial images in a single row.\n",
    "    Uses the eps value and the predicted label as axis titles.\n",
    "\n",
    "    Parameters:\n",
    "        model (ImageNetClassifier, torch.nn.Module):\n",
    "            The image classification model. This is a torch.nn.Module, so you can call its forward method using `model()`.\n",
    "            Also has a `.predict` method that returns the index of the predicted label.\n",
    "\n",
    "        image (torch.tensor): The original image corresponding to the adversarial examples.\n",
    "\n",
    "        adv_images (List[torch.tensor]): A list containing the adversarial examples to visualize.\n",
    "\n",
    "        eps_values (List[float]): The list of epsilon values corresponding to each adversarial example in adv_images.\n",
    "\n",
    "    Hint: \n",
    "        - matplotlib expects a channels last format\n",
    "        - The model works with normalized images. Before visualizing the images, you have to invert the normalization\n",
    "        using `unnormalize()`\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(len(adv_images) + 1, 1) # create a subplot for plotting the images. It creates a figure (fig) and a list of axes (axes). The number of axes is set to be len(adv_images) + 1, which allows space for the original image and all the adversarial images\n",
    "    predictions = model.predict(torch.cat([image] + adv_images)) # make predictions for the original image and all the adversarial images combined by concatenating image and adv_images into a single tensor\n",
    "\n",
    "    axes[0].imshow(unnormalize_image(image).squeeze().permute(1,2,0).detach().numpy()) # display the original image on the first axis axes[0], unnormalize_image(image): unnormalizes the image, squeeze(): removes any singleton dimensions from the tensor, permute(1,2,0): change the tensor's dimension order to match the expected channels-last format, detach().numpy(): converts the tensor to a NumPy array for visualization\n",
    "    axes[0].axis('off') # turn off the axis (axis labels) for the original image.\n",
    "    axes[0].set_title(f'eps: {0.0}\\npred: {convert_idx_to_label(predictions[0].item())}') # sets the title for the original image\n",
    "    plt.tight_layout() # adjust the subplot layout for better spacing\n",
    "    for i, ax in enumerate(axes[1:]): # for loop that iterates through a sequence of axes, skipping the first one\n",
    "        ax.imshow(unnormalize_image(adv_images[i]).squeeze().permute(1,2,0).detach().numpy()) # set up the current axis (ax) to display an image similar to aboveeffectively reducing dimensionality if there are dimensions with size 1\n",
    "        ax.axis('off') # turn off the axis (axis labels) for the current axis (ax)\n",
    "        ax.set_title(f'eps: {eps_values[i]}\\npred: {convert_idx_to_label(predictions[i+1].item())}') # set title for the current axis\n",
    "        plt.tight_layout() # adjust the layout of the subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9740f",
   "metadata": {},
   "source": [
    "**e)** Now we load and preprocess a test image, for which adversarial examples should be created as described down below. The custom `ImageNetClassifier()` from the custom `cnn_classifier` module is initialized as the prediction model. Perform the following steps: \n",
    "\n",
    "- Make a prediction for the preprocessed and normalized test input image using the `model.predict()` method. Set `return_probs=True` and return both the  predicted class (`y_pred`) and the predicted class probability (`y_prob`)\n",
    "- Print the predicted class label by passing `y_pred.item()` to the `convert_idx_to_label()` function\n",
    "- Print the predicted class probability `y_prob.item()`\n",
    "- Check if the predicted class index (`y_pred`) matches the expected class index of 13 (`torch.tensor([13])`), the true label of the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb43ee",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b5c463a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading and preprocessing of the test image using the costum modules\n",
    "image = load_test_image()\n",
    "image_preprocessed = preprocess_image(image)\n",
    "image_preprocessed_norm = normalize_image(image_preprocessed).unsqueeze(0)\n",
    "\n",
    "# Initialize the model\n",
    "model = ImageNetClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be89eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e2201ea",
   "metadata": {},
   "source": [
    "**f)** Generate five adversarial images using the `create_adversarial_function()`on the preprocessed and normalized image and the `ImageNetClassifier()` as the input model. Then plot the adversarial examples using the `plot_adversarials()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a911cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad5818a",
   "metadata": {},
   "source": [
    "**g)** What is the difference between counterfactuals and adversarial examples? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302a5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76da12b7",
   "metadata": {},
   "source": [
    "<hr style=\"border:1.5px solid gray\"> </hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
