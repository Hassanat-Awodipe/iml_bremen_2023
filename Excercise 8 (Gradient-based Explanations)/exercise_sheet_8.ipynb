{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efcfe277",
   "metadata": {},
   "source": [
    "# Interpretable Machine Learning\n",
    "## Exercise Sheet: 8 Gradient-based Explanations\n",
    "### Presentation date: 08.01.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab010d5",
   "metadata": {},
   "source": [
    "Gradient-based approaches are among the most popular methods used for interpreting neural networks.\n",
    "They leverage white-box access to the neural network, as they rely on backpropagation to compute the\n",
    "gradients of an input with respect to a prediction. The intuition behind using gradients for explanatory\n",
    "purposes is that they tell us, how sensitive the prediction is to small changes in the input. In this assignment,\n",
    "we will generate different gradient-based explanations for a ResNet18 model pretrained on the ImageNet\n",
    "Dataset by 1) applying off-the-shelf methods and 2) implementing gradient-based feature attribution from\n",
    "scratch.\n",
    "\n",
    "Please also download the utils and classifiers folder from the studIP/Github folder, because we will use some preimplemented methods from those folders and the test_image for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17ee090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install torchvision\n",
    "#!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093f2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from utils.styled_plot import plt\n",
    "from utils.dataset import load_test_image, preprocess_image, normalize_image, convert_idx_to_label\n",
    "from classifiers.cnn_classifier import ImageNetClassifier\n",
    "from captum.attr import Saliency, IntegratedGradients, NoiseTunnel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82648716",
   "metadata": {},
   "source": [
    "### Excercise 1: Applying Gradient-based Feature Attribution Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f352215",
   "metadata": {},
   "source": [
    "In this first task, the goal is to use off-the-shelf implementations of different gradient-based feature attribution\n",
    "methods to obtain explanations. Here, we apply different methods implemented in `Captum`, a model\n",
    "interpretability library for `PyTorch`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6fda07",
   "metadata": {},
   "source": [
    "#### 1.1 Gradient\n",
    "Complete `get_gradient` to produce a saliency map based on the gradient with respect to the model’s prediction\n",
    "as the target class, for a given input image. Use `captum.attr.Saliency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53bc2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(model, image):\n",
    "    \"\"\"\n",
    "    Uses captum's 'Saliency' method to generate a saliency map based on the gradient w.r.t. \n",
    "    the model's prediction as the target. See also: https://captum.ai/api/saliency.html\n",
    "\n",
    "    Parameters:\n",
    "        model (ImageNetClassifier): Image classification model. Has a 'predict' method that \n",
    "                                    returns the predicted label index for an image.\n",
    "        image (torch.tensor): Single image with shape (1, 3, ?, ?).\n",
    "\n",
    "    Returns:\n",
    "        attribution (torch.tensor): The gradient, of the same shape as the image.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb708e22",
   "metadata": {},
   "source": [
    "#### 1.2 Integrated Gradients\n",
    "The Integrated Gradients method interpolates gradients between a non-informative baseline $\\bar{x}$ and the actual input $x$. Complete `get_integrated_gradients` to produce the Integrated Gradients with respect to the model’s prediction as the target class, for a given input image. Use `captum.attr.IntegratedGradients`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b382c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integrated_gradients(model, image):\n",
    "    \"\"\"\n",
    "    Uses captum's IntegratedGradients method to generate an attribution map w.r.t. the model's prediction as the target. \n",
    "    Uses zeros (black image) as the baseline, that are normalized using 'normalize_image'.\n",
    "    See also: https://captum.ai/api/integrated_gradients.html\n",
    "\n",
    "    Parameters:\n",
    "        model (ImageNetClassifier): Image classification model. Has a 'predict' method that returns the predicted label index \n",
    "                                    for an image.\n",
    "        image (torch.tensor): Single image with shape (1, 3, ?, ?).\n",
    "\n",
    "    Returns:\n",
    "        attributions (torch.tensor): The integrated gradients, of the same shape as the image.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183b607",
   "metadata": {},
   "source": [
    "#### 1.3 SmoothGrad\n",
    "The SmoothGrad method helps to reduce noise by adding noise. Complete `get_smoothgrad` to produce a\n",
    "smoothed saliency map for a given input image. Use `captum.attr.NoiseTunnel` in combination with `captum.attr.Saliency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad52f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smoothgrad(model, image, num_samples=10, stdevs=0.3):\n",
    "    \"\"\"\n",
    "    Uses captum's NoiseTunnel and Saliency method to generate a saliency map using SmoothGrad, based on the gradient w.r.t. \n",
    "    the model's prediction as the target. See also: https://captum.ai/api/noise_tunnel.html\n",
    "\n",
    "    Parameters:\n",
    "        model (ImageNetClassifier): Image classification model. Has a 'predict' method.\n",
    "        image (torch.tensor): Single image with shape (1, 3, ?, ?).\n",
    "        num_samples (int): Number of SmoothGrad samples to use.\n",
    "        stdevs (float): Standard deviation for the smoothgrad samples\n",
    "\n",
    "    Returns:\n",
    "        attributions (torch.tensor): The gradient, of the same shape as the image.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089bc3d",
   "metadata": {},
   "source": [
    "#### 1.4 Preparing Feature Attribution Maps for Visualization\n",
    "The resulting feature attribution maps have the same dimensions as the input to the neural network. For\n",
    "visualization purposes, we often aggregate them to smaller dimensions to produce heatmap-like outputs.\n",
    "Complete `aggregate_attribution` that aggregates an attribution map with three color channels to a single\n",
    "color channel by summing over the channel dimension.\n",
    "For proper visualization, we additionally want to normalize the attribution maps. Complete `normalize_attribution` that first takes the absolute values of the attributions, then normalizes them into the range\n",
    "[0, 1] by subtracting the minimum and afterwards dividing by the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_attribution(attribution):\n",
    "    \"\"\"\n",
    "    Aggregates the channel dimension of a feature attribution tensor via summation.\n",
    "    Additionally, removes the batch dimension (dim 0).\n",
    "\n",
    "    Parameters:\n",
    "        attribution (torch.tensor): Feature attribution of shape (1, 3, ?, ?)\n",
    "\n",
    "    Returns:\n",
    "        attribution (torch.tensor): The aggregated attribution of shape (?, ?)\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "609950c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_attribution(attribution):\n",
    "    \"\"\"\n",
    "    Takes the absolute value of the feature attribution, then normalizes to the range [0, 1] by first subtracting the minimum \n",
    "    and then dividing by the maximum afterwards.\n",
    "\n",
    "    Parameters:\n",
    "        attribution (torch.tensor): Feature attribution of shape (?, ?)\n",
    "\n",
    "    Returns:\n",
    "        attribution (torch.tensor): The absolute, normalized attribution of shape (?, ?)\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc156b",
   "metadata": {},
   "source": [
    "#### 1.5 Visualizing Feature Attributions\n",
    "After generating all the explanations, we of course want to plot them. Complete the `plot_attributions`\n",
    "function that plots the image and the generated attributions in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca25162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attributions(plt, image, attributions, method_names):\n",
    "    \"\"\"\n",
    "    Visualizes an image and a list of corresponding feature attributions by plotting them in a single row.\n",
    "\n",
    "    Parameters:\n",
    "        image (torch.tensor): Single image with shape (3, ?, ?)\n",
    "        attributions (List[torch.tensor]): List of feature attributions, each of shape (?, ?)\n",
    "        method_names (List[str]): List of method names corresponding to the attributions. Used as subfigure titles.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Hint: iterate over the axes. Use imshow() to plot images. Matplotlib expects a channels last format. Optionally turn of \n",
    "    the axis labeling using ax.axis('off') .\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(attributions) + 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b737ed",
   "metadata": {},
   "source": [
    "#### 1.6. Example\n",
    "Apply the explanation methods on the test_image.png and plot the results. As a model we use ImageNetClassifier. Interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70f3638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: \"junco, snowbird\". Confidence: 94.83%\n",
      "Run `get_gradient` ...\n",
      "Run `get_integrated_gradients` ...\n",
      "Run `get_smoothgrad` ...\n",
      "Run `plot_attributions` ...\n"
     ]
    }
   ],
   "source": [
    "image = load_test_image()\n",
    "image_preprocessed = preprocess_image(image)\n",
    "image_preprocessed_norm = normalize_image(image_preprocessed).unsqueeze(0)\n",
    "\n",
    "model = ImageNetClassifier()\n",
    "\n",
    "y_pred, y_prob = model.predict(image_preprocessed_norm, return_probs=True)\n",
    "print(f'Predicted class: \"{convert_idx_to_label(y_pred.item())}\". Confidence: {y_prob.item() * 100:.2f}%')\n",
    "\n",
    "print('Run `get_gradient` ...')\n",
    "#TODO: apply get_gradient\n",
    "\n",
    "print('Run `get_integrated_gradients` ...')\n",
    "#TODO: apply get_integrated_gradients\n",
    "\n",
    "print('Run `get_smoothgrad` ...')\n",
    "#TODO: apply get_smoothgrad\n",
    "\n",
    "print('Run `plot_attributions` ...')\n",
    "#TODO: plot attributions using aggregate_attribution, normalize_attribution and plot_attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09606ec",
   "metadata": {},
   "source": [
    "### 2 Gradient-based Feature Attribution from Scratch\n",
    "Now, the task is to implement the methods from task 1 from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6165c11",
   "metadata": {},
   "source": [
    "#### 2.1 Saliency Maps \n",
    "\n",
    "Complete `get_custom_gradient` that implements the simple gradient method to compute a feature attribution\n",
    "map:\n",
    "\n",
    "\\begin{align}\n",
    "A= \\frac{\\partial f(\\bf{x})_c}{\\partial \\bf{x}}\n",
    "\\end{align}\n",
    "\n",
    "where $A$ is the resulting feature attribution map, f is the neural network model, x is an input image and $c$\n",
    "is the index of the class we are interested in. That means $f(\\bf{x})_c$ is the neural network output corresponding\n",
    "to class $c$. Here, the class we are interested in is the one that is predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24722841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_gradient(model, image, absolute=False):\n",
    "    \"\"\"\n",
    "    Generates a saliency map based on the input gradient w.r.t. the model's prediction as the target.\n",
    "\n",
    "    Parameters:\n",
    "        model (ImageNetClassifier): Image classification model. Has a 'predict' method that returns the predicted label \n",
    "                                    index for an image.\n",
    "        image (torch.tensor): Single image with shape (1, 3, ?, ?).\n",
    "        absolute (bool): If True, return the absolute value of the gradients. If False, return the signed gradients.\n",
    "\n",
    "    Returns:\n",
    "        attribution (torch.tensor): The gradient, of the same shape as the image.\n",
    "\n",
    "    Hint: Use torch.autograd.grad . The model is a torch.nn.Module, so you can call model(x) to get the network's outputs.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66a683",
   "metadata": {},
   "source": [
    "#### 2.2. Integrated Gradients\n",
    "Now we want to implement the Integrated Gradients method from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d704c",
   "metadata": {},
   "source": [
    "#### 2.2.1 Path Computation\n",
    "First, complete the `get_path` function, that creates a path of images. The path starts from a baseline, ends\n",
    "with the actual image and is filled with intermediate samples in between. This path essentially contains the\n",
    "samples\n",
    "\n",
    "\\begin{align}\n",
    "\\tilde{x}_{\\alpha} = \\bar{x} + \\alpha (x-\\bar{x})\n",
    "\\end{align}\n",
    "for increasing $\\alpha \\in [0,1]$ such that you obtain a series of $\\tilde{x}_{\\alpha}$ as discussed in the lecture. The alphas should\n",
    "be evenly spaced in the unit interval. Here, we choose a black image as the baseline $\\bar{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6878475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(image, baseline, num_samples):\n",
    "    \"\"\"\n",
    "    Generate an attribution map based on the Integrated Gradients method, w.r.t. the model's prediction.\n",
    "    Uses zeros (black image) as the baseline, that are normalized using 'normalize_image'.\n",
    "\n",
    "    Parameters:\n",
    "        image (torch.tensor): Single image with shape (1, 3, ?, ?).\n",
    "        baseline (torch.tensor): Baseline image with same shape as image.\n",
    "        num_samples (int): The number of samples on the path.\n",
    "\n",
    "    Returns:\n",
    "        path (List[torch.tensor]): A list of length num_samples, containing the images on the path starting from the \n",
    "        baseline (path[0]) and ending with the image (path[-1]).\n",
    "\n",
    "    Hint: Create alphas using torch.linspace.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e8c41",
   "metadata": {},
   "source": [
    "#### 2.2.2 Integrated Gradient Computation\n",
    "Next, complete `get_custom_integrated` gradients to generate the integrated gradients using the following\n",
    "equation:\n",
    "\n",
    "\\begin{align}\n",
    "A=(x-\\bar{x})\\int_{\\alpha=0}^1 \\frac{\\partial f(\\bf{x})_c}{\\partial \\tilde{\\bf{x}}}\\Bigg|_{ \\tilde{\\bf{x}}=\\bar{\\bf{x}}+\\alpha(\\bf{x}-\\bar{\\bf{x}})}\n",
    "\\end{align}\n",
    "where the integral is approximated by averaging the gradients over the samples in the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095fa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_integrated_gradients(model, image, num_samples):\n",
    "    \"\"\"\n",
    "    Generate an attribution map based on the Integrated Gradients method, w.r.t. the model's prediction.\n",
    "    Uses zeros (black image) as the baseline, that are normalized using 'normalize_image'.\n",
    "\n",
    "    Parameters:\n",
    "        model (ImageNetClassifier): Image classification model. Has a 'predict' method that returns the predicted label \n",
    "                                    index for an image.\n",
    "        image (torch.tensor): Single image with shape (1, 3, ?, ?).\n",
    "        num_samples (int): The number of samples on the path.\n",
    "    Returns:\n",
    "        attributions (torch.tensor): The integrated gradients, of the same shape as the image.\n",
    "\n",
    "    Hint: Iterate over the path of images, remember what you did in 'get_custom_gradient'.\n",
    "    Use torch.autograd.grad . The model is a torch.nn.Module, so you can call model(x) to get the network's outputs.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a17d94",
   "metadata": {},
   "source": [
    "#### 2.3. Example\n",
    "Apply your implemented explanation methods on the test_image.png and plot the results. As a model we use ImageNetClassifier. Compare to task 1 and interpret your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e24ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: \"junco, snowbird\". Confidence: 94.83%\n",
      "Run `get_custom_gradient` ...\n",
      "Run `get_custom_integrated_gradients` ...\n",
      "Run `plot_attributions` ...\n"
     ]
    }
   ],
   "source": [
    "image = load_test_image()\n",
    "image_preprocessed = preprocess_image(image)\n",
    "image_preprocessed_norm = normalize_image(image_preprocessed).unsqueeze(0)\n",
    "\n",
    "model = ImageNetClassifier()\n",
    "\n",
    "y_pred, y_prob = model.predict(image_preprocessed_norm, return_probs=True)\n",
    "print(f'Predicted class: \"{convert_idx_to_label(y_pred.item())}\". Confidence: {y_prob.item() * 100:.2f}%')\n",
    "assert y_pred == torch.tensor([13])\n",
    "assert torch.allclose(y_prob, torch.tensor([0.9483]), atol=1e-4)\n",
    "\n",
    "print('Run `get_custom_gradient` ...')\n",
    "#TODO: Apply get_custom_gradient with absolut=True and False\n",
    "\n",
    "print('Run `get_custom_integrated_gradients` ...')\n",
    "#TODO: Apply get_custom_integrated_gradients\n",
    "\n",
    "print('Run `plot_attributions` ...')\n",
    "#TODO: plot attributions using aggregate_attribution, normalize_attribution and plot_attributions from task 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
